{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "PCA steps for data downscaling projet, dominant PCs to be exported in an array since that is all we really work with in the main downscalling file (in an effort to reduce memory load)<br>\n",
    "\n",
    "World data preprocessing in this file because i didnt feel as if a new netCDF file was necessary for that data as it already loads rather quickly and doesn't take up much space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in HRDPS and world data (for now still just working on pressure)\n",
    "P_world= xr.open_dataset(\"psl_NAM-22_CCCma-CanESM2_rcp45_r1i1p1_CCCma-CanRCM4_r2_day_20160101-20201231.nc\")\n",
    "hrdps = xr.open_dataset('HRDPSsubset.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first lets do some quick processing of the hrdps data\n",
    "hrdps_lat = hrdps.nav_lat.values\n",
    "hrdps_lon = hrdps.nav_lon.values\n",
    "p_temp = hrdps.slp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get them into a shape we can work in\n",
    "hrdps_lat = hrdps_lat[0,:,:].flatten()\n",
    "hrdps_lon = hrdps_lon[0,:,:].flatten()\n",
    "\n",
    "P_hrdps = np.empty((np.shape(p_temp)[1]*np.shape(p_temp)[2],np.shape(p_temp)[0]))\n",
    "for i in range(np.shape(p_temp)[0]):\n",
    "    P_hrdps[:,i] = np.reshape(p_temp[i],(np.shape(p_temp)[1]*np.shape(p_temp)[2],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all nan with 101325\n",
    "P_hrdps = (pd.DataFrame(P_hrdps).fillna(101325)).to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for preprocessing of world data\n",
    "\n",
    "#trim the world dataset to be for right time extent\n",
    "#want days between June 1 2018 and June 30 2018\n",
    "P_world = P_world.sel(time=slice('2016-01-01 12:00:00', '2019-12-31 12:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now extract the data you want from the CanRCM4 xarray and trim them according to lat and lon of the HRDPS data\n",
    "#first decide on range you want to work within for CanRCM4 data, want to overlap the HRDPS data by 10% of the max distance (y)\n",
    "buffer = (max(hrdps_lat)-min(hrdps_lat))*0.1\n",
    "\n",
    "lon = P_world.lon.values.flatten()\n",
    "lat = P_world.lat.values.flatten()\n",
    "index = []\n",
    "\n",
    "#first find idexes that fit into lon range and lat range\n",
    "for i in range(len(lon)):\n",
    "    if lon[i] > (min(hrdps_lon)-buffer) and lon[i] < (max(hrdps_lon)+buffer) and lat[i] > (min(hrdps_lat)-buffer) and lat[i] < (max(hrdps_lat)+buffer):\n",
    "        index.append(i)\n",
    "\n",
    "#now make new lat, and lon\n",
    "lat_RCM = []\n",
    "lon_RCM = []\n",
    "\n",
    "for i in index:\n",
    "    lat_RCM.append(lat[i])\n",
    "    lon_RCM.append(lon[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now convert data to 2D and use the idices found in the previous step to trim it\n",
    "P2d = np.empty((np.shape(P_world.psl.values)[1]*np.shape(P_world.psl.values)[2],np.shape(P_world.psl.values)[0]))\n",
    "for i in range(np.shape(P_world.psl.values)[0]):\n",
    "    P2d[:,i] = np.reshape(P_world.psl.values[i],(np.shape(P_world.psl.values)[1]*np.shape(P_world.psl.values)[2],))\n",
    "\n",
    "P_RCM = np.empty((len(index),np.shape(P_world.psl.values)[0]))\n",
    "\n",
    "for i in range(np.shape(P_hrdps)[1]):\n",
    "    for j in range(len(index)):\n",
    "        P_RCM[j,i] = P2d[index[j],i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "NOTE : before export find out how to limit range of the PCs so that you don't need to normalize afterwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA on the world data\n",
    "#looking for dominant spatial patterns to be eigenvectors and how those spatial patterns evelove over the month to the the PCs)\n",
    "#need to take the transpose of the matrix \n",
    "\n",
    "data = P_RCM.T\n",
    "\n",
    "n_modes = np.min(np.shape(data))\n",
    "pca = PCA(n_components = n_modes)\n",
    "RCM_PCs = pca.fit_transform(data)\n",
    "RCM_eigvecs = pca.components_\n",
    "RMC_fracVar = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the relevant arrays to CSV\n",
    "numpy.savetxt(\"CanRCM4_PCs.csv\", RCM_PCs, delimiter=\",\")\n",
    "numpy.savetxt(\"CanRCM4_eig.csv\", RCM_eigvecs, delimiter=\",\")\n",
    "numpy.savetxt(\"CanRCM4_fracVar.csv\", RCM_fracVar, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA on the HRDPS data \n",
    "data = P_hrdps.T\n",
    "\n",
    "n_modes = np.min(np.shape(data))\n",
    "pca = PCA(n_components = n_modes)\n",
    "hrdps_PCs = pca.fit_transform(data)\n",
    "hrdps_eigvecs = pca.components_\n",
    "hrdps_fracVar = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the relevant arrays to CSV\n",
    "numpy.savetxt(\"HRDPS_PCs.csv\", hrdps_PCs, delimiter=\",\")\n",
    "numpy.savetxt(\"HRDPS_eig.csv\", hrdps_eigvecs, delimiter=\",\")\n",
    "numpy.savetxt(\"HRDPS_fracVar.csv\", hrdps_fracVar, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eosc510",
   "language": "python",
   "name": "eosc510"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
