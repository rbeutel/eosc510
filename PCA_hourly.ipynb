{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "PCA steps for hourly HRDPS data, dominant PCs to be exported in an array (in an effort to reduce memory load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import time\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in HRDPS\n",
    "hrdps = xr.open_dataset(\"hrdps_hourly_postSep2014.nc\")\n",
    "\n",
    "#lets go ahead and trim the hrdps dataset so it fits more snuggly in a year\n",
    "#we're also going to remove the leap days here so that seasonal cycle calcs will work\n",
    "a = hrdps.sel(time_counter=slice('2015-01-01T00:00:00.000000000', '2016-02-28T23:00:00.000000000'))\n",
    "b = hrdps.sel(time_counter=slice('2016-03-01T00:00:00.000000000', '2020-02-28T23:00:00.000000000'))\n",
    "c = hrdps.sel(time_counter=slice('2020-03-01T00:00:00.000000000', '2020-12-31T23:00:00.000000000'))\n",
    "hrdps= xr.concat([a,b,c],dim='time_counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first lets do some quick processing of the hrdps data\n",
    "#hrdps_lat = hrdps.nav_lat.sel(time_counter=hrdps.time_counter[0]).values.flatten()\n",
    "#hrdps_lon = hrdps.nav_lon.sel(time_counter=hrdps.time_counter[0]).values.flatten()\n",
    "#p_temp = hrdps.atmpres.values\n",
    "u_temp = hrdps.u_wind.values\n",
    "v_temp = hrdps.v_wind.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cummulative time -U wind done (s):1611685311.9968083\n",
      "cummulative time -V wind done (s):1611685371.8305454\n"
     ]
    }
   ],
   "source": [
    "#get pressure into a shape we can work in\n",
    "# P = np.empty((np.shape(p_temp)[1]*np.shape(p_temp)[2],np.shape(p_temp)[0]))\n",
    "# for i in range(np.shape(p_temp)[0]):\n",
    "#     P[:,i] = np.reshape(p_temp[i],(np.shape(p_temp)[1]*np.shape(p_temp)[2],))\n",
    "# print(f\"cummulative time -pressure done (s):\"+str(time.time()))\n",
    "    \n",
    "U = np.empty((np.shape(u_temp)[1]*np.shape(u_temp)[2],np.shape(u_temp)[0]))\n",
    "for i in range(np.shape(u_temp)[0]):\n",
    "    U[:,i] = np.reshape(u_temp[i],(np.shape(u_temp)[1]*np.shape(u_temp)[2],))\n",
    "print(f\"cummulative time -U wind done (s):\"+str(time.time()))\n",
    "    \n",
    "V = np.empty((np.shape(v_temp)[1]*np.shape(v_temp)[2],np.shape(v_temp)[0]))\n",
    "for i in range(np.shape(v_temp)[0]):\n",
    "    V[:,i] = np.reshape(v_temp[i],(np.shape(v_temp)[1]*np.shape(v_temp)[2],))\n",
    "print(f\"cummulative time -V wind done (s):\"+str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all nan with 101 kPa or 0 m/s\n",
    "# P = (pd.DataFrame(P).fillna(101000)).to_numpy()\n",
    "U = (pd.DataFrame(U).fillna(0)).to_numpy()\n",
    "V = (pd.DataFrame(V).fillna(0)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert U and V wind into wind speed and direction\n",
    "speed = np.sqrt(np.add(np.square(U),np.square(V)))\n",
    "direc = np.arctan2(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now de-mean the dataset (If the mean isn't removed then it will show up in the mode 1 EOF and give disproportionate weight to the mode 1 percent variance)\n",
    "#calculate seasonal signal for each grid point\n",
    "\n",
    "nyears = 6\n",
    "hours = 365*24\n",
    "\n",
    "# #pressure\n",
    "# seasonal = np.empty((np.shape(P)[0],hours))\n",
    "# for ii in range(len(P)):\n",
    "#     seasonal[ii,:] = np.mean(np.reshape(P[ii,:],(nyears,hours)),axis=0)\n",
    "\n",
    "# #repeat the seasonal cycle for all years\n",
    "# seasonal_all = np.tile(seasonal,(1,nyears))\n",
    "\n",
    "# #remove seasonal cycle from the original data (calculate anomalies)\n",
    "# P_anom = P - seasonal_all\n",
    "\n",
    "# #save seasonal cycle so that you can add mean back to data in reconstruction\n",
    "# np.savetxt(\"P_seasonal.csv\", seasonal, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed\n",
    "seasonal = np.empty((np.shape(speed)[0],hours))\n",
    "for ii in range(len(speed)):\n",
    "    seasonal[ii,:] = np.mean(np.reshape(speed[ii,:],(nyears,hours)),axis=0)\n",
    "\n",
    "#repeat the seasonal cycle for all years\n",
    "seasonal_all = np.tile(seasonal,(1,nyears))\n",
    "\n",
    "#remove seasonal cycle from the original data (calculate anomalies)\n",
    "speed_anom = speed - seasonal_all\n",
    "\n",
    "#save seasonal cycle so that you can add mean back to data in reconstruction\n",
    "np.savetxt(\"speed_seasonal.csv\", seasonal, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#direction\n",
    "seasonal = np.empty((np.shape(direc)[0],hours))\n",
    "for ii in range(len(direc)):\n",
    "    seasonal[ii,:] = np.mean(np.reshape(direc[ii,:],(nyears,hours)),axis=0)\n",
    "\n",
    "#repeat the seasonal cycle for all years\n",
    "seasonal_all = np.tile(seasonal,(1,nyears))\n",
    "\n",
    "#remove seasonal cycle from the original data (calculate anomalies)\n",
    "direc_anom = direc - seasonal_all\n",
    "\n",
    "#save seasonal cycle so that you can add mean back to data in reconstruction\n",
    "np.savetxt(\"direc_seasonal.csv\", seasonal, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PCA on the HRDPS data \n",
    "# data = P_anom.T\n",
    "\n",
    "# n_modes = np.min(np.shape(data))\n",
    "# pca = PCA(n_components = n_modes)\n",
    "# PCs = pca.fit_transform(data)\n",
    "# eigvecs = pca.components_\n",
    "# fracVar = pca.explained_variance_ratio_\n",
    "\n",
    "# #export the relevant arrays to CSV\n",
    "# np.savetxt(\"P_hrdps_hourly_PCs.csv\", PCs, delimiter=\",\")\n",
    "# np.savetxt(\"P_hrdps_hourly_eigvecs.csv\",eigvecs, delimiter=\",\")\n",
    "# np.savetxt(\"P_hrdps_hourly_fracVar.csv\",fracVar, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = speed_anom.T\n",
    "\n",
    "n_modes = np.min(np.shape(data))\n",
    "pca = PCA(n_components = n_modes)\n",
    "PCs = pca.fit_transform(data)\n",
    "eigvecs = pca.components_\n",
    "fracVar = pca.explained_variance_ratio_\n",
    "\n",
    "np.savetxt(\"speed_hrdps_hourly_PCs.csv\", PCs, delimiter=\",\")\n",
    "np.savetxt(\"speed_hrdps_hourly_eigvecs.csv\", eigvecs, delimiter=\",\")\n",
    "np.savetxt(\"speed_hrdps_hourly_fracVar.csv\", fracVar, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = direc_anom.T\n",
    "\n",
    "n_modes = np.min(np.shape(data))\n",
    "pca = PCA(n_components = n_modes)\n",
    "PCs = pca.fit_transform(data)\n",
    "eigvecs = pca.components_\n",
    "fracVar = pca.explained_variance_ratio_\n",
    "\n",
    "np.savetxt(\"direc_hrdps_hourly_PCs.csv\", PCs, delimiter=\",\")\n",
    "np.savetxt(\"direc_hrdps_hourly_eigvecs.csv\", eigvecs, delimiter=\",\")\n",
    "np.savetxt(\"direc_hrdps_hourly_fracVar.csv\", fracVar, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save date arrays that you want to work with\n",
    "dates = hrdps.time_counter.values\n",
    "np.savetxt(\"hrdps_times.csv\",dates,delimiter=\",\",fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eosc510",
   "language": "python",
   "name": "eosc510"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
